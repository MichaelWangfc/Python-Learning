{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3.4. Encoding categorical features\n",
    "Often features are not given as continuous values but categorical. For example a person could have features \n",
    "[\"male\", \"female\"], [\"from Europe\", \"from US\", \"from Asia\"], [\"uses Firefox\", \"uses Chrome\", \"uses Safari\", \"uses Internet Explorer\"]. \n",
    "Such features can be efficiently coded as integers, \n",
    "for instance:\n",
    "[\"male\", \"from US\", \"uses Internet Explorer\"] could be expressed as [0, 1, 3] \n",
    "while [\"female\", \"from Asia\", \"uses Chrome\"] would be [1, 2, 1].\n",
    "\n",
    "[\"male\", \"from Europe\", \"uses Internet Explorer\"] could be expressed as [0, 0, 3] \n",
    "[\"female\", \"from US\", \"uses Firefox\"] could be expressed as [1, 1, 0]\n",
    "[\"male\", \"from Asia\", \"uses Chrome\"] could be expressed as [0, 2, 1]\n",
    "[\"female\", \"from Europe\", \"uses Safari\"] would be [1, 0, 2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>continent</th>\n",
       "      <th>web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>from Europe</td>\n",
       "      <td>uses Internet Explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>from US</td>\n",
       "      <td>uses Firefox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>from Asia</td>\n",
       "      <td>uses Chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>from Europe</td>\n",
       "      <td>uses Safari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender    continent                     web\n",
       "0    male  from Europe  uses Internet Explorer\n",
       "1  female      from US            uses Firefox\n",
       "2    male    from Asia             uses Chrome\n",
       "3  female  from Europe             uses Safari"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=np.array([[\"male\", \"from Europe\", \"uses Internet Explorer\"],[\"female\", \"from US\", \"uses Firefox\"],[\"male\", \"from Asia\", \"uses Chrome\"],\\\n",
    "             [\"female\", \"from Europe\", \"uses Safari\"]],dtype = str)\n",
    "print type(df)\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "columns = ['gender','continent','web']\n",
    "df.columns= columns\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_dummies() function \n",
    "Pandas is a popular Python library inspired by data frames in R. It allows easier manipulation of tabular numeric and non-numeric data. Downsides: not very intuitive, somewhat steep learning curve. For any questions you may have, Google + StackOverflow combo works well as a source of answers.\n",
    "\n",
    "UPDATE: Turns out that Pandas has get_dummies() function which does what we’re after. The following code will replace categorical columns with their one-hot representations:\n",
    "We’ll use Pandas to load the data, do some cleaning and send it to Scikit-learn’s DictVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>continent_from Asia</th>\n",
       "      <th>continent_from Europe</th>\n",
       "      <th>continent_from US</th>\n",
       "      <th>web_uses Chrome</th>\n",
       "      <th>web_uses Firefox</th>\n",
       "      <th>web_uses Internet Explorer</th>\n",
       "      <th>web_uses Safari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender_female  gender_male  continent_from Asia  continent_from Europe  \\\n",
       "0            0.0          1.0                  0.0                    1.0   \n",
       "1            1.0          0.0                  0.0                    0.0   \n",
       "2            0.0          1.0                  1.0                    0.0   \n",
       "3            1.0          0.0                  0.0                    1.0   \n",
       "\n",
       "   continent_from US  web_uses Chrome  web_uses Firefox  \\\n",
       "0                0.0              0.0               0.0   \n",
       "1                1.0              0.0               1.0   \n",
       "2                0.0              1.0               0.0   \n",
       "3                0.0              0.0               0.0   \n",
       "\n",
       "   web_uses Internet Explorer  web_uses Safari  \n",
       "0                         1.0              0.0  \n",
       "1                         0.0              0.0  \n",
       "2                         0.0              0.0  \n",
       "3                         0.0              1.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_transform = [ 'gender','continent','web' ]\n",
    "df_with_dummies = pd.get_dummies(df,columns = cols_to_transform)\n",
    "df_with_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#([0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoder is another option. The difference is as follows:\n",
    "\n",
    "OneHotEncoder takes as input categorical values encoded as integers - you can get them from LabelEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoder: It is used to transform non-numerical labels to numerical labels (or nominal categorical variables). \n",
    "Numerical labels are always between 0 and n_classes-1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "le= sklearn.preprocessing.LabelEncoder()\n",
    "a= le.fit( [\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "le.classes_\n",
    "le.transform([\"paris\", \"paris\", \"tokyo\"])\n",
    "# or directly fit and transform \n",
    "le.fit_transform( [\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "\n",
    "# le.inverse_transform([2,2,1])\n",
    "# le.\n",
    "\n",
    "\n",
    "# enc = sklearn.preprocessing.OneHotEncoder()\n",
    "# #enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])  \n",
    "# enc.fit(df)  \n",
    "#OneHotEncoder(categorical_features='all', dtype=<... 'numpy.float64'>,handle_unknown='error', n_values='auto', sparse=True)\n",
    "# enc.transform([[0, 1, 3]]).toarray()\n",
    "# array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4.3.5.  Imputing missing values before building an estimator\n",
    "\n",
    "\n",
    "This example shows that imputing the missing values can give better results\n",
    "than discarding the samples containing any missing value.\n",
    "Imputing does not always improve the predictions, so please check via cross-validation.\n",
    "Sometimes dropping rows or using marker values is more effective.\n",
    "\n",
    "Missing values can be replaced by the mean, the median or the most frequent\n",
    "value using the ``strategy`` hyper-parameter.\n",
    "The median is a more robust estimator for data with high magnitude variables\n",
    "which could dominate results (otherwise known as a 'long tail').\n",
    "\n",
    "Script output::\n",
    "\n",
    "  Score with the entire dataset = 0.56\n",
    "  Score without the samples containing missing values = 0.48\n",
    "  Score after imputation of the missing values = 0.55\n",
    "\n",
    "In this case, imputing helps the classifier get close to the original score.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "dataset = load_boston()\n",
    "X_full, y_full = dataset.data, dataset.target\n",
    "n_samples = X_full.shape[0]\n",
    "n_features = X_full.shape[1]\n",
    "print n_samples, n_features\n",
    "y_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with the entire dataset = 0.56\n"
     ]
    }
   ],
   "source": [
    "# Estimate the score on the entire dataset, with no missing values\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "score = cross_val_score(estimator, X_full, y_full).mean()\n",
    "print(\"Score with the entire dataset = %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  2.0  5.0\n",
      "2  3.0  6.0\n",
      "3  NaN  NaN\n",
      "4  NaN  NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A    2\n",
       "B    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1,2,3, np.nan, np.nan])\n",
    "s1 = pd.Series([1,2,3, '',''])\n",
    "s2 = pd.Series([1,2,3, None,None])\n",
    "s2.isnull().sum()\n",
    "s3= pd.DataFrame({'A':[1,2,3, None,None],'B':[4,5,6, np.nan, np.nan]})\n",
    "print s3\n",
    "s3.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X_full).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full_df= pd.DataFrame(X_full)\n",
    "X_full_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379.0\n",
      "506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# Add missing values in 75% of the lines\n",
    "missing_rate = 0.75\n",
    "n_missing_samples = np.floor(n_samples * missing_rate)\n",
    "missing_samples = np.hstack((np.zeros(n_samples - n_missing_samples,\n",
    "                                      dtype=np.bool),\n",
    "                             np.ones(n_missing_samples,\n",
    "                                     dtype=np.bool)))\n",
    "print n_missing_samples\n",
    "print missing_samples.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(379L,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng.shuffle(missing_samples)\n",
    "\n",
    "missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "\n",
    "missing_samples\n",
    "missing_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without the samples containing missing values = 0.54\n"
     ]
    }
   ],
   "source": [
    "# Estimate the score without the lines containing missing values\n",
    "X_filtered = X_full[~missing_samples, :]\n",
    "y_filtered = y_full[~missing_samples]\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "score = cross_val_score(estimator, X_filtered, y_filtered).mean()\n",
    "print(\"Score without the samples containing missing values = %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00, ...,\n",
       "          1.53000000e+01,   3.96900000e+02,   4.98000000e+00],\n",
       "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
       "          1.78000000e+01,   3.96900000e+02,   9.14000000e+00],\n",
       "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
       "          0.00000000e+00,   3.92830000e+02,   4.03000000e+00],\n",
       "       ..., \n",
       "       [  6.07600000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
       "          2.10000000e+01,   3.96900000e+02,   0.00000000e+00],\n",
       "       [  1.09590000e-01,   0.00000000e+00,   1.19300000e+01, ...,\n",
       "          2.10000000e+01,   3.93450000e+02,   6.48000000e+00],\n",
       "       [  4.74100000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
       "          2.10000000e+01,   3.96900000e+02,   7.88000000e+00]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the score after imputation of the missing values\n",
    "X_missing = X_full.copy()\n",
    "X_missing[np.where(missing_samples)[0], missing_features] = 0\n",
    "y_missing = y_full.copy()\n",
    "# print missing_samples\n",
    "# print np.where(missing_samples)[0]\n",
    "X_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = Pipeline([(\"imputer\", Imputer(missing_values=0,\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"forest\", RandomForestRegressor(random_state=0,\n",
    "                                                       n_estimators=100))])\n",
    "score = cross_val_score(estimator, X_missing, y_missing).mean()\n",
    "print(\"Score after imputation of the missing values = %.2f\" % score)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
